{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import xlrd\n",
    "import os\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'\n",
    "import pickle\n",
    "import random\n",
    "from tensorflow import set_random_seed\n",
    "import numpy as np\n",
    "seed_value =10\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "set_random_seed(seed_value)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation, Dropout,RepeatVector,TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_for_variable(variables,excel_path):\n",
    "    \n",
    "    month_convert={\n",
    "            4:\"Arp\",\n",
    "            5:\"May\",\n",
    "            6:\"Jun\",\n",
    "            7:\"Jul\",\n",
    "            8:\"Aug\",\n",
    "            9:\"Sep\",\n",
    "            10:\"Oct\",\n",
    "            11:\"Nov\",\n",
    "            12:\"Dec\",\n",
    "            1:\"Jan\",\n",
    "            2:\"Feb\",\n",
    "            3:\"Mar\"\n",
    "        }\n",
    "    workbook = xlrd.open_workbook(excel_path) #read input\n",
    "    worksheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    keys={}\n",
    "    keys[\"Month\"]=[]\n",
    "\n",
    "    #find all keys\n",
    "    forbid={}\n",
    "    for i in range(3,worksheet.nrows):#for each row\n",
    "        forbid[i]=1\n",
    "        for var in variables:\n",
    "            if var.lower() in str(worksheet.cell(i,5).value).lower(): #column3 is product name and column 5 is variable\n",
    "                key=str(worksheet.cell(i,5).value)+\"-\"+str(worksheet.cell(i,3).value)\n",
    "                keys[key]=[]\n",
    "                break\n",
    "\n",
    "    j=9 #date column begin from 9 in format\n",
    "\n",
    "    while j<worksheet.ncols:\n",
    "        date3=str(xlrd.xldate.xldate_as_datetime(worksheet.cell(2,j).value,workbook.datemode))\n",
    "        final_date=date3[5]+date3[6]+\"-\"+date3[8]+date3[9]+\"-\"+date3[0]+date3[1]+date3[2]+date3[3]\n",
    "        ok=0\n",
    "        for i in range(3,worksheet.nrows):#for each row\n",
    "            bol=str(type(worksheet.cell(i,j).value))==\"<class 'float'>\"\n",
    "            if str(worksheet.cell(i,j).value)=='x':\n",
    "                forbid[i]=0\n",
    "            if bol==1:\n",
    "                for var in variables:\n",
    "                    if var.lower() in str(worksheet.cell(i,5).value).lower():\n",
    "                        key=str(worksheet.cell(i,5).value)+\"-\"+str(worksheet.cell(i,3).value)\n",
    "                        keys[key].append(worksheet.cell(i,j).value)\n",
    "                        ok=1\n",
    "                        break\n",
    "            elif forbid[i]:\n",
    "                for var in variables:\n",
    "                    if var.lower() in str(worksheet.cell(i,5).value).lower():\n",
    "                        key=str(worksheet.cell(i,5).value)+\"-\"+str(worksheet.cell(i,3).value)\n",
    "                        keys[key].append(0.0)\n",
    "                        ok=1\n",
    "                        break\n",
    "        if ok==1:\n",
    "            keys[\"Month\"].append(final_date)\n",
    "        j+=1\n",
    "\n",
    "    #convert it to proper pandas format\n",
    "    colname=[]\n",
    "    leng=0\n",
    "    for key in keys:\n",
    "        colname.append(key)\n",
    "        leng=len(keys[key])\n",
    "    datarow=[]\n",
    "    for w in range(0,leng):\n",
    "        rw=[]\n",
    "        for key in keys:\n",
    "            rw.append(keys[key][w])\n",
    "        rw.append(float(w))\n",
    "        datarow.append(rw)\n",
    "    colname.append('Index')\n",
    "    dataset = pd.DataFrame(datarow,columns=colname).set_index('Index')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_product(dataset,product_name):\n",
    "    column_name='Net Migrations(Norm)-%s'%product_name #product_key_name \n",
    "    dataset=pd.DataFrame(dataset[column_name])\n",
    "    plt.plot(dataset)\n",
    "    plt.show()\n",
    "    return dataset,column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset,column_name,model_path):\n",
    "    dataframe = dataset\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    scalerfile = os.path.join(model_path,'scaler-%s.sav'%column_name)\n",
    "    pickle.dump(scaler, open(scalerfile, 'wb'))\n",
    "    return dataset,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainX, trainY,model_save_path):\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences= True,input_shape=( 1,look_back)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=30, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=30))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mean_squared_error'])\n",
    "    print(model.summary())\n",
    "    history = model.fit(trainX, trainY, epochs=300, batch_size=6, verbose=1)\n",
    "    model.save(model_save_path)\n",
    "    print(\"Model Saved at -\",model_save_path)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def predict_values(testX,no_of_pred,model_save_path,scaler_save_path):\n",
    "    scaler = pickle.load(open(scaler_save_path, 'rb'))\n",
    "    final_output = []\n",
    "    model = load_model(model_save_path)\n",
    "    for i in range(0,no_of_pred):\n",
    "        testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[0]))\n",
    "        testPredict = model.predict(testX)\n",
    "        testX = np.array(testPredict[0])\n",
    "        output = scaler.inverse_transform(testPredict)\n",
    "        output = output[0].tolist()\n",
    "        final_output.append(output[0])\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path =\"models\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset with needed columns and its values\n",
    "variables=[\"Net Migration\"] # variable name\n",
    "excel_path = 'PrivatizedDataforParticipants.xlsx'\n",
    "dataset = get_dataset_for_variable(variables,excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Net Migrations(Norm)-Panther</th>\n",
       "      <th>Net Migrations(Norm)-Leopard</th>\n",
       "      <th>Net Migrations(Norm)-Lion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>04-01-2016</td>\n",
       "      <td>1.474487</td>\n",
       "      <td>-1.517807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>05-01-2016</td>\n",
       "      <td>1.465958</td>\n",
       "      <td>-1.499497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>06-01-2016</td>\n",
       "      <td>0.511313</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>07-01-2016</td>\n",
       "      <td>0.688626</td>\n",
       "      <td>0.169296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>08-01-2016</td>\n",
       "      <td>0.473906</td>\n",
       "      <td>0.630261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Month  Net Migrations(Norm)-Panther  Net Migrations(Norm)-Leopard  \\\n",
       "Index                                                                           \n",
       "0.0    04-01-2016                      1.474487                     -1.517807   \n",
       "1.0    05-01-2016                      1.465958                     -1.499497   \n",
       "2.0    06-01-2016                      0.511313                      0.549954   \n",
       "3.0    07-01-2016                      0.688626                      0.169296   \n",
       "4.0    08-01-2016                      0.473906                      0.630261   \n",
       "\n",
       "       Net Migrations(Norm)-Lion  \n",
       "Index                             \n",
       "0.0                          0.0  \n",
       "1.0                          0.0  \n",
       "2.0                          0.0  \n",
       "3.0                          0.0  \n",
       "4.0                          0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product name(Panther/Leopard/Lion):leopard\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "product_name = str(input(\"Enter the product name(Panther/Leopard/Lion):\")).title()\n",
    "dataset,column_name = get_dataset_for_product(dataset,product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,scaler = normalize_dataset(dataset,column_name,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1 # change the look bach period here\n",
    "trainX, trainY = create_dataset(dataset, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking last 6 values for cross validation\n",
    "valX = trainX[-6:]\n",
    "trainX = trainX[:-6]\n",
    "valY = trainY[-6:]\n",
    "trainY = trainY[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35, 1), (35,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 30)             3840      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 5s 134ms/step - loss: 0.2938 - mean_squared_error: 0.2938\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.2720 - mean_squared_error: 0.2720\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.2500 - mean_squared_error: 0.2500\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.2259 - mean_squared_error: 0.2259\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.1979 - mean_squared_error: 0.1979\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.1693 - mean_squared_error: 0.1693\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1396 - mean_squared_error: 0.1396\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.1058 - mean_squared_error: 0.1058\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0725 - mean_squared_error: 0.0725\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0490 - mean_squared_error: 0.0490\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0292 - mean_squared_error: 0.0292\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - mean_squared_error: 0.0303\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0225 - mean_squared_error: 0.0225\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0281 - mean_squared_error: 0.0281\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0271 - mean_squared_error: 0.0271\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0214 - mean_squared_error: 0.0214\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 884us/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0247 - mean_squared_error: 0.0247\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 941us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 208/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 209/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0209 - mean_squared_error: 0.0209\n",
      "Epoch 210/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 211/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0264 - mean_squared_error: 0.0264\n",
      "Epoch 212/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 969us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 213/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 214/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 215/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
      "Epoch 216/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 217/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 218/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 219/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 220/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 221/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 222/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0225 - mean_squared_error: 0.0225\n",
      "Epoch 223/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 224/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 225/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
      "Epoch 226/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 227/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
      "Epoch 228/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0214 - mean_squared_error: 0.0214\n",
      "Epoch 229/300\n",
      "35/35 [==============================] - 0s 769us/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
      "Epoch 230/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 231/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 232/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 233/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 234/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 235/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 236/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 237/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 238/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 239/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
      "Epoch 240/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 241/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 242/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 243/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 244/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 245/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
      "Epoch 246/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 247/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 248/300\n",
      "35/35 [==============================] - 0s 798us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 249/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 250/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 251/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0212 - mean_squared_error: 0.0212\n",
      "Epoch 252/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 253/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 254/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 255/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 256/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 257/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 258/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 259/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 260/300\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 261/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
      "Epoch 262/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 263/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 264/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 265/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 266/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 267/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 268/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
      "Epoch 269/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
      "Epoch 270/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 271/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
      "Epoch 272/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 273/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 274/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 275/300\n",
      "35/35 [==============================] - 0s 826us/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 276/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 277/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 278/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
      "Epoch 279/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 280/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 281/300\n",
      "35/35 [==============================] - 0s 798us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 282/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 283/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 969us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 285/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 286/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 287/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
      "Epoch 288/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 289/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 290/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 291/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 292/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 293/300\n",
      "35/35 [==============================] - 0s 855us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 294/300\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 295/300\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 296/300\n",
      "35/35 [==============================] - 0s 883us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 297/300\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 298/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 299/300\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 300/300\n",
      "35/35 [==============================] - 0s 940us/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Model Saved at - models\\Net Migrations(Norm)-Leopard.h5\n"
     ]
    }
   ],
   "source": [
    "model_save_path = os.path.join(model_path,column_name+\".h5\")\n",
    "scaler_save_path = os.path.join(model_path,'scaler-%s.sav'%column_name)\n",
    "history = train_model(trainX, trainY,model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation\n",
    "no_of_pred = 6 #change forecast horizon here\n",
    "testX = np.array([trainY[-1]]) # taking the last value to predict next no_of_pred predictions\n",
    "final_output = predict_values(testX,no_of_pred,model_save_path,scaler_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013895739801228046 -0.6080824\n",
      "0.020779533311724663 -0.65562457\n",
      "0.02600879967212677 0.16126461\n",
      "0.029984405264258385 2.1352262\n",
      "0.033008504658937454 -0.1545048\n",
      "0.03530926629900932 0.14680937\n",
      "6.930566372311863\n"
     ]
    }
   ],
   "source": [
    "#calculating MAPE SCORE\n",
    "def cal_mape(ypred,y):\n",
    "    mape = max(0, 1 - abs(y-ypred)/abs(y))\n",
    "    return mape\n",
    "scores =[]\n",
    "for y_pred,y in zip(final_output,valY):\n",
    "    y = scaler.inverse_transform(y.reshape(-1, 1))[0][0]\n",
    "    print(y_pred,y)\n",
    "    scores.append(cal_mape(y_pred,y))\n",
    "print(100 * sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## final prediciton\n",
    "no_of_pred = 6 # prediction horizon\n",
    "testX = np.array([valY[-1]]) # take the last month value to predict next 6\n",
    "testX = scaler.transform(np.array(testX).astype('float32').reshape(-1, 1))\n",
    "model_save_path = os.path.join(model_path,column_name+\".h5\")\n",
    "scaler_save_path = os.path.join(model_path,'scaler-%s.sav'%column_name)\n",
    "final_output = predict_values(testX,no_of_pred,model_save_path,scaler_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43643009662628174,\n",
       " 0.3495137393474579,\n",
       " 0.28063204884529114,\n",
       " 0.22649836540222168,\n",
       " 0.18424150347709656,\n",
       " 0.1514333039522171]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## checkin constraint that sum of all products should be close to zer0\n",
    "# no_of_pred = 6 # prediction horizon\n",
    "# final_outputs = {}\n",
    "# products =['Lion','Panther','Leopard']\n",
    "# variables=[\"Net Migration\"]\n",
    "# look_back = 1\n",
    "# for product in products:\n",
    "#     print(product)\n",
    "    \n",
    "#     excel_path = 'PrivatizedDataforParticipants.xlsx'\n",
    "#     dataset = get_dataset_for_variable(variables,excel_path)\n",
    "    \n",
    "#     dataset,column_name = get_dataset_for_product(dataset,product)\n",
    "    \n",
    "#     dataset,scaler = normalize_dataset(dataset,column_name,model_path)\n",
    "    \n",
    "#     trainX, trainY = create_dataset(dataset, look_back)\n",
    "    \n",
    "#     model_save_path = os.path.join(model_path,column_name+\".h5\")\n",
    "#     history = train_model(trainX, trainY,model_save_path)\n",
    "    \n",
    "#     testX = np.array([trainY[-1]]) # take the last month value to predict next 6\n",
    "#     scaler_save_path = os.path.join(model_path,'scaler-%s.sav'%column_name)\n",
    "    \n",
    "#     final_output = predict_values(testX,no_of_pred,model_save_path,scaler_save_path)\n",
    "#     final_outputs[product]=final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_outputs)\n",
    "# outputs =[]\n",
    "# for key,value in final_outputs.items():\n",
    "#     outputs.append(value)\n",
    "# list(map(sum, zip(*outputs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
